{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Generation with DCGAN\n",
        "This tutorial shows how to generate images using [DCGAN](https://arxiv.org/pdf/1511.06434.pdf). We use MNIST dataset for this tutorial, but any other dataset of reasonable size can be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install nnabla-ext-cuda100\n",
        "!git clone https://github.com/sony/nnabla-examples.git\n",
        "%cd nnabla-examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start by importing dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "import nnabla as nn\n",
        "import nnabla.logger as logger\n",
        "import nnabla.functions as F\n",
        "import nnabla.parametric_functions as PF\n",
        "import nnabla.solvers as S\n",
        "import nnabla.utils.save as save\n",
        "\n",
        "import os\n",
        "\n",
        "from utils.neu.checkpoint_util import save_checkpoint, load_checkpoint\n",
        "from utils.neu.save_nnp import save_nnp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's define a function to download and load MNIST. This function will pass image-label pairs to DataSource class, which we will define next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import struct\n",
        "import zlib\n",
        "\n",
        "from nnabla.logger import logger\n",
        "from nnabla.utils.data_iterator import data_iterator\n",
        "from nnabla.utils.data_source import DataSource\n",
        "from nnabla.utils.data_source_loader import download\n",
        "\n",
        "\n",
        "def load_mnist(train=True):\n",
        "    '''\n",
        "    Load MNIST dataset images and labels from the original page by Yan LeCun or the cache file.\n",
        "    Args:\n",
        "        train (bool): The testing dataset will be returned if False. Training data has 60000 images, while testing has 10000 images.\n",
        "    Returns:\n",
        "        numpy.ndarray: A shape of (#images, 1, 28, 28). Values in [0.0, 1.0].\n",
        "        numpy.ndarray: A shape of (#images, 1). Values in {0, 1, ..., 9}.\n",
        "    '''\n",
        "    if train:\n",
        "        image_uri = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "        label_uri = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "    else:\n",
        "        image_uri = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "        label_uri = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "    logger.info('Getting label data from {}.'.format(label_uri))\n",
        "    r = download(label_uri)\n",
        "    data = zlib.decompress(r.read(), zlib.MAX_WBITS | 32)\n",
        "    _, size = struct.unpack('>II', data[0:8])\n",
        "    labels = np.frombuffer(data[8:], np.uint8).reshape(-1, 1)\n",
        "    r.close()\n",
        "    logger.info('Getting label data done.')\n",
        "\n",
        "    logger.info('Getting image data from {}.'.format(image_uri))\n",
        "    r = download(image_uri)\n",
        "    data = zlib.decompress(r.read(), zlib.MAX_WBITS | 32)\n",
        "    _, size, height, width = struct.unpack('>IIII', data[0:16])\n",
        "    images = np.frombuffer(data[16:], np.uint8).reshape(\n",
        "        size, 1, height, width)\n",
        "    r.close()\n",
        "    logger.info('Getting image data done.')\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we define a data iterator to pass the images and labels to actual computation graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class MnistDataSource(DataSource):\n",
        "    '''\n",
        "    Get data directly from MNIST dataset from Internet(yann.lecun.com).\n",
        "    '''\n",
        "\n",
        "    def _get_data(self, position):\n",
        "        image = self._images[self._indexes[position]]\n",
        "        label = self._labels[self._indexes[position]]\n",
        "        return (image, label)\n",
        "\n",
        "    def __init__(self, train=True, shuffle=False, rng=None):\n",
        "        super(MnistDataSource, self).__init__(shuffle=shuffle)\n",
        "        self._train = train\n",
        "\n",
        "        self._images, self._labels = load_mnist(train)\n",
        "\n",
        "        self._size = self._labels.size\n",
        "        self._variables = ('x', 'y')\n",
        "        if rng is None:\n",
        "            rng = np.random.RandomState(313)\n",
        "        self.rng = rng\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        if self._shuffle:\n",
        "            self._indexes = self.rng.permutation(self._size)\n",
        "        else:\n",
        "            self._indexes = np.arange(self._size)\n",
        "        super(MnistDataSource, self).reset()\n",
        "\n",
        "    @property\n",
        "    def images(self):\n",
        "        \"\"\"Get copy of whole data with a shape of (N, 1, H, W).\"\"\"\n",
        "        return self._images.copy()\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "        \"\"\"Get copy of whole label with a shape of (N, 1).\"\"\"\n",
        "        return self._labels.copy()\n",
        "\n",
        "def data_iterator_mnist(batch_size,\n",
        "                        train=True,\n",
        "                        rng=None,\n",
        "                        shuffle=True,\n",
        "                        with_memory_cache=False,\n",
        "                        with_file_cache=False):\n",
        "    '''\n",
        "    Provide DataIterator with :py:class:`MnistDataSource`\n",
        "    with_memory_cache and with_file_cache option's default value is all False,\n",
        "    because :py:class:`MnistDataSource` is able to store all data into memory.\n",
        "    For example,\n",
        "    .. code-block:: python\n",
        "        with data_iterator_mnist(True, batch_size) as di:\n",
        "            for data in di:\n",
        "                SOME CODE TO USE data.\n",
        "    '''\n",
        "    return data_iterator(MnistDataSource(train=train, shuffle=shuffle, rng=rng),\n",
        "                         batch_size,\n",
        "                         rng,\n",
        "                         with_memory_cache,\n",
        "                         with_file_cache)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generative adversarial networks and its variations, including DCGAN, have adversarial setting, in which generator network and discriminator network compete against each other. Let's define our generator network first. We implement the network with 4 consecutive deconvolution layers, each of which is followed by batch normalization and ELU non-linear activation. Then, we apply convolutional layer followed by hyperbolic tangent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def generator(z, maxh=256, test=False, output_hidden=False):\n",
        "    \"\"\"\n",
        "    Building generator network which takes (B, Z, 1, 1) inputs and generates\n",
        "    (B, 1, 28, 28) outputs.\n",
        "    \"\"\"\n",
        "    # Define shortcut functions\n",
        "    def bn(x):\n",
        "        # Batch normalization\n",
        "        return PF.batch_normalization(x, batch_stat=not test)\n",
        "\n",
        "    def upsample2(x, c):\n",
        "        # Twice upsampling with deconvolution.\n",
        "        return PF.deconvolution(x, c, kernel=(4, 4), pad=(1, 1), stride=(2, 2), with_bias=False)\n",
        "\n",
        "    assert maxh / 4 > 0\n",
        "    with nn.parameter_scope(\"gen\"):\n",
        "        # (Z, 1, 1) --> (256, 4, 4)\n",
        "        with nn.parameter_scope(\"deconv1\"):\n",
        "            d1 = F.elu(bn(PF.deconvolution(z, maxh, (4, 4), with_bias=False)))\n",
        "        # (256, 4, 4) --> (128, 8, 8)\n",
        "        with nn.parameter_scope(\"deconv2\"):\n",
        "            d2 = F.elu(bn(upsample2(d1, maxh / 2)))\n",
        "        # (128, 8, 8) --> (64, 16, 16)\n",
        "        with nn.parameter_scope(\"deconv3\"):\n",
        "            d3 = F.elu(bn(upsample2(d2, maxh / 4)))\n",
        "        # (64, 16, 16) --> (32, 28, 28)\n",
        "        with nn.parameter_scope(\"deconv4\"):\n",
        "            # Convolution with kernel=4, pad=3 and stride=2 transforms a 28 x 28 map\n",
        "            # to a 16 x 16 map. Deconvolution with those parameters behaves like an\n",
        "            # inverse operation, i.e. maps 16 x 16 to 28 x 28.\n",
        "            d4 = F.elu(bn(PF.deconvolution(\n",
        "                d3, maxh / 8, (4, 4), pad=(3, 3), stride=(2, 2), with_bias=False)))\n",
        "        # (32, 28, 28) --> (1, 28, 28)\n",
        "        with nn.parameter_scope(\"conv5\"):\n",
        "            x = F.tanh(PF.convolution(d4, 1, (3, 3), pad=(1, 1)))\n",
        "    if output_hidden:\n",
        "        return x, [d1, d2, d3, d4]\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then define the other part of adversarial setting, discriminator network. We can think of discriminator as the reverse of generator network, where we have 4 consecutive convolutional layers instead of deconvolution layers. All convolutional layers are again followed by batch normalization and ELU activation, except for the last convolutional layer. Finally, we apply affine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def discriminator(x, maxh=256, test=False, output_hidden=False):\n",
        "    \"\"\"\n",
        "    Building discriminator network which maps a (B, 1, 28, 28) input to\n",
        "    a (B, 1).\n",
        "    \"\"\"\n",
        "    # Define shortcut functions\n",
        "    def bn(xx):\n",
        "        # Batch normalization\n",
        "        return PF.batch_normalization(xx, batch_stat=not test)\n",
        "\n",
        "    def downsample2(xx, c):\n",
        "        return PF.convolution(xx, c, (3, 3), pad=(1, 1), stride=(2, 2), with_bias=False)\n",
        "\n",
        "    assert maxh / 8 > 0\n",
        "    with nn.parameter_scope(\"dis\"):\n",
        "        # (1, 28, 28) --> (32, 16, 16)\n",
        "        with nn.parameter_scope(\"conv1\"):\n",
        "            c1 = F.elu(bn(PF.convolution(x, maxh / 8,\n",
        "                                         (3, 3), pad=(3, 3), stride=(2, 2), with_bias=False)))\n",
        "        # (32, 16, 16) --> (64, 8, 8)\n",
        "        with nn.parameter_scope(\"conv2\"):\n",
        "            c2 = F.elu(bn(downsample2(c1, maxh / 4)))\n",
        "        # (64, 8, 8) --> (128, 4, 4)\n",
        "        with nn.parameter_scope(\"conv3\"):\n",
        "            c3 = F.elu(bn(downsample2(c2, maxh / 2)))\n",
        "        # (128, 4, 4) --> (256, 4, 4)\n",
        "        with nn.parameter_scope(\"conv4\"):\n",
        "            c4 = bn(PF.convolution(c3, maxh, (3, 3),\n",
        "                                   pad=(1, 1), with_bias=False))\n",
        "        # (256, 4, 4) --> (1,)\n",
        "        with nn.parameter_scope(\"fc1\"):\n",
        "            f = PF.affine(c4, 1)\n",
        "    if output_hidden:\n",
        "        return f, [c1, c2, c3, c4]\n",
        "    return f\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are ready to get into the training part. Let's first define the context to use GPU and define hyperparameters. We also need to define the noise variable z, which is fed into the generator network to generate fake images, which in turn will be fed to the discriminator network. We define separate losses for generator and discriminator networks, both with sigmoid cross entropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get context.\n",
        "from nnabla.ext_utils import get_extension_context\n",
        "ctx = get_extension_context('cudnn')\n",
        "nn.set_default_context(ctx)\n",
        "\n",
        "# Create CNN network for both training and testing.\n",
        "# TRAIN\n",
        "\n",
        "# Fake path\n",
        "batch_size = 64\n",
        "learning_rate = 0.0002\n",
        "max_iter = 20000\n",
        "weight_decay = 0.0001\n",
        "\n",
        "z = nn.Variable([batch_size, 100, 1, 1])\n",
        "fake = generator(z)\n",
        "fake.persistent = True  # Not to clear at backward\n",
        "pred_fake = discriminator(fake)\n",
        "loss_gen = F.mean(F.sigmoid_cross_entropy(\n",
        "    pred_fake, F.constant(1, pred_fake.shape)))\n",
        "fake_dis = fake.get_unlinked_variable(need_grad=True)\n",
        "pred_fake_dis = discriminator(fake_dis)\n",
        "loss_dis = F.mean(F.sigmoid_cross_entropy(\n",
        "    pred_fake_dis, F.constant(0, pred_fake_dis.shape)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Likewise, let's define a variable for real images, also to be input to discriminator network. Note that discriminator loss will have to account for both fake and real images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Real path\n",
        "x = nn.Variable([batch_size, 1, 28, 28])\n",
        "pred_real = discriminator(x)\n",
        "loss_dis += F.mean(F.sigmoid_cross_entropy(pred_real,\n",
        "                                           F.constant(1, pred_real.shape)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also define separate solvers for generator and discriminator. Following the paper, we used [Adam](https://arxiv.org/pdf/1412.6980.pdf) for both. Let's also define monitor variables to keep track of the progress. This will also save some of the generated fake images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create Solver.\n",
        "solver_gen = S.Adam(learning_rate, beta1=0.5)\n",
        "solver_dis = S.Adam(learning_rate, beta1=0.5)\n",
        "with nn.parameter_scope(\"gen\"):\n",
        "    solver_gen.set_parameters(nn.get_parameters())\n",
        "with nn.parameter_scope(\"dis\"):\n",
        "    solver_dis.set_parameters(nn.get_parameters())\n",
        "start_point = 0\n",
        "\n",
        "# If necessary, load weights and solver state info from specified checkpoint files.\n",
        "# start_point = load_checkpoint(\n",
        "#     specified_checkpoint, {\"gen\": solver_gen, \"dis\": solver_dis})\n",
        "\n",
        "# Create monitor.\n",
        "import nnabla.monitor as M\n",
        "monitor_path = 'tmp.monitor.dcgan'\n",
        "monitor = M.Monitor(monitor_path)\n",
        "monitor_loss_gen = M.MonitorSeries(\"Generator loss\", monitor, interval=10)\n",
        "monitor_loss_dis = M.MonitorSeries(\n",
        "    \"Discriminator loss\", monitor, interval=10)\n",
        "monitor_time = M.MonitorTimeElapsed(\"Time\", monitor, interval=100)\n",
        "monitor_fake = M.MonitorImageTile(\n",
        "    \"Fake images\", monitor, normalize_method=lambda x: (x + 1) / 2.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to go! We call the data iterator that we defined earlier, and define training loop, in which we alternate between generator update and discriminator update."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = data_iterator_mnist(batch_size, True)\n",
        "\n",
        "# Training loop.\n",
        "for i in range(start_point, max_iter):\n",
        "\n",
        "    # Training forward\n",
        "    image, _ = data.next()\n",
        "    x.d = image / 255. - 0.5  # [0, 255] to [-1, 1]\n",
        "    z.d = np.random.randn(*z.shape)\n",
        "\n",
        "    # Generator update.\n",
        "    solver_gen.zero_grad()\n",
        "    loss_gen.forward(clear_no_need_grad=True)\n",
        "    loss_gen.backward(clear_buffer=True)\n",
        "    solver_gen.weight_decay(weight_decay)\n",
        "    solver_gen.update()\n",
        "    monitor_fake.add(i, fake)\n",
        "    monitor_loss_gen.add(i, loss_gen.d.copy())\n",
        "\n",
        "    # Discriminator update.\n",
        "    solver_dis.zero_grad()\n",
        "    loss_dis.forward(clear_no_need_grad=True)\n",
        "    loss_dis.backward(clear_buffer=True)\n",
        "    solver_dis.weight_decay(weight_decay)\n",
        "    solver_dis.update()\n",
        "    monitor_loss_dis.add(i, loss_dis.d.copy())\n",
        "    monitor_time.add(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we're done training, let's see how the generated fake images evolved throughout the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import Image, display\n",
        "for i in range(20):\n",
        "    print(\"At iteration\",(i+1)*1000-1)\n",
        "    display(Image('tmp.monitor.dcgan/Fake-images/{:06d}.png'.format((i+1)*1000-1)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU", 
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
