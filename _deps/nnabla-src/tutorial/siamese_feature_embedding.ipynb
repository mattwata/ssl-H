{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RekDGy3vSCOM",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, we will show you how to perform feature embedding with [Sieamese Neural Networks](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf) using NNabla. Siamese Neural Networks were originally proposed for one-shot image recognition task, and can also be useful for feature embedding, where it learns by considering what makes 2 images similar or dissimilar, as we will see below.\n",
        "\n",
        "We will use images of MNIST for this tutorial. At the end of the tutorial, you will be able to visually see how the model has learned to embed each class of digit.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install nnabla-ext-cuda100\n",
        "!git clone https://github.com/sony/nnabla-examples.git\n",
        "%cd nnabla-examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start by importing dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from contextlib import contextmanager\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import nnabla as nn\n",
        "import nnabla.functions as F\n",
        "import nnabla.parametric_functions as PF\n",
        "import nnabla.solver as S\n",
        "from nnabla.logger import logger\n",
        "\n",
        "from utils.neu.save_nnp import save_nnp\n",
        "import nnabla.utils.save as save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also define data iterator for MNIST. You can disregard the details for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "import struct\n",
        "import zlib\n",
        "\n",
        "from nnabla.logger import logger\n",
        "from nnabla.utils.data_iterator import data_iterator\n",
        "from nnabla.utils.data_source import DataSource\n",
        "from nnabla.utils.data_source_loader import download\n",
        "\n",
        "\n",
        "def load_mnist(train=True):\n",
        "    '''\n",
        "    Load MNIST dataset images and labels from the original page by Yan LeCun or the cache file.\n",
        "    Args:\n",
        "        train (bool): The testing dataset will be returned if False. Training data has 60000 images, while testing has 10000 images.\n",
        "    Returns:\n",
        "        numpy.ndarray: A shape of (#images, 1, 28, 28). Values in [0.0, 1.0].\n",
        "        numpy.ndarray: A shape of (#images, 1). Values in {0, 1, ..., 9}.\n",
        "    '''\n",
        "    if train:\n",
        "        image_uri = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "        label_uri = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "    else:\n",
        "        image_uri = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "        label_uri = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "    logger.info('Getting label data from {}.'.format(label_uri))\n",
        "    r = download(label_uri)\n",
        "    data = zlib.decompress(r.read(), zlib.MAX_WBITS | 32)\n",
        "    _, size = struct.unpack('>II', data[0:8])\n",
        "    labels = np.frombuffer(data[8:], np.uint8).reshape(-1, 1)\n",
        "    r.close()\n",
        "    logger.info('Getting label data done.')\n",
        "\n",
        "    logger.info('Getting image data from {}.'.format(image_uri))\n",
        "    r = download(image_uri)\n",
        "    data = zlib.decompress(r.read(), zlib.MAX_WBITS | 32)\n",
        "    _, size, height, width = struct.unpack('>IIII', data[0:16])\n",
        "    images = np.frombuffer(data[16:], np.uint8).reshape(\n",
        "        size, 1, height, width)\n",
        "    r.close()\n",
        "    logger.info('Getting image data done.')\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "class MnistDataSource(DataSource):\n",
        "    '''\n",
        "    Get data directly from MNIST dataset from Internet(yann.lecun.com).\n",
        "    '''\n",
        "\n",
        "    def _get_data(self, position):\n",
        "        image = self._images[self._indexes[position]]\n",
        "        label = self._labels[self._indexes[position]]\n",
        "        return (image, label)\n",
        "\n",
        "    def __init__(self, train=True, shuffle=False, rng=None):\n",
        "        super(MnistDataSource, self).__init__(shuffle=shuffle)\n",
        "        self._train = train\n",
        "\n",
        "        self._images, self._labels = load_mnist(train)\n",
        "\n",
        "        self._size = self._labels.size\n",
        "        self._variables = ('x', 'y')\n",
        "        if rng is None:\n",
        "            rng = np.random.RandomState(313)\n",
        "        self.rng = rng\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        if self._shuffle:\n",
        "            self._indexes = self.rng.permutation(self._size)\n",
        "        else:\n",
        "            self._indexes = np.arange(self._size)\n",
        "        super(MnistDataSource, self).reset()\n",
        "\n",
        "    @property\n",
        "    def images(self):\n",
        "        \"\"\"Get copy of whole data with a shape of (N, 1, H, W).\"\"\"\n",
        "        return self._images.copy()\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "        \"\"\"Get copy of whole label with a shape of (N, 1).\"\"\"\n",
        "        return self._labels.copy()\n",
        "\n",
        "def data_iterator_mnist(batch_size,\n",
        "                        train=True,\n",
        "                        rng=None,\n",
        "                        shuffle=True,\n",
        "                        with_memory_cache=False,\n",
        "                        with_file_cache=False):\n",
        "    '''\n",
        "    Provide DataIterator with :py:class:`MnistDataSource`\n",
        "    with_memory_cache and with_file_cache option's default value is all False,\n",
        "    because :py:class:`MnistDataSource` is able to store all data into memory.\n",
        "    For example,\n",
        "    .. code-block:: python\n",
        "        with data_iterator_mnist(True, batch_size) as di:\n",
        "            for data in di:\n",
        "                SOME CODE TO USE data.\n",
        "    '''\n",
        "    return data_iterator(MnistDataSource(train=train, shuffle=shuffle, rng=rng),\n",
        "                         batch_size,\n",
        "                         rng,\n",
        "                         with_memory_cache,\n",
        "                         with_file_cache)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define a simple [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) for MNIST. We stack two convolution layers with kernel size of 5x5, each of which is followed by non-linear activation function (ELU) and an average pooling layer. We then apply three fully-connected (affine) layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def mnist_lenet_feature(image, test=False):\n",
        "    \"\"\"\n",
        "    Construct LeNet for MNIST.\n",
        "    \"\"\"\n",
        "    c1 = F.elu(PF.convolution(image, 20, (5, 5), name='conv1'))\n",
        "    c1 = F.average_pooling(c1, (2, 2))\n",
        "    c2 = F.elu(PF.convolution(c1, 50, (5, 5), name='conv2'))\n",
        "    c2 = F.average_pooling(c2, (2, 2))\n",
        "    c3 = F.elu(PF.affine(c2, 500, name='fc3'))\n",
        "    c4 = PF.affine(c3, 10, name='fc4')\n",
        "    c5 = PF.affine(c4, 2, name='fc_embed')\n",
        "    return c5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we define a function that takes two images, inputs each image to LeNet defined above, and computes the squared error from the output features of each input image. In other words, we input two images to the same network that shares weights. This is why the model is called Siamese network!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def mnist_lenet_siamese(x0, x1, test=False):\n",
        "    \"\"\"\"\"\"\n",
        "    h0 = mnist_lenet_feature(x0, test)\n",
        "    h1 = mnist_lenet_feature(x1, test)  # share weights\n",
        "    h = F.squared_error(h0, h1)\n",
        "    p = F.sum(h, axis=1)\n",
        "    return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also define our loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def contrastive_loss(sd, l, margin=1.0, eps=1e-4):\n",
        "    sim_cost = l * sd\n",
        "    dissim_cost = (1 - l) * \\\n",
        "        (F.maximum_scalar(margin - (sd + eps) ** (0.5), 0) ** 2)\n",
        "    return sim_cost + dissim_cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since Siamese Neural Networks take two images as inputs, we need to slightly modify the data iterator defined above so that it provides two images and corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class MnistSiameseDataIterator(object):\n",
        "\n",
        "    def __init__(self, itr0, itr1):\n",
        "        self.itr0 = itr0\n",
        "        self.itr1 = itr1\n",
        "\n",
        "    def next(self):\n",
        "        x0, l0 = self.itr0.next()\n",
        "        x1, l1 = self.itr1.next()\n",
        "        sim = (l0 == l1).astype(np.int).flatten()\n",
        "        return x0 / 255., x1 / 255., sim\n",
        "\n",
        "\n",
        "def siamese_data_iterator(batch_size, train, rng=None):\n",
        "    itr0 = data_iterator_mnist(batch_size, train=train, rng=rng, shuffle=True)\n",
        "    itr1 = data_iterator_mnist(batch_size, train=train, rng=rng, shuffle=True)\n",
        "    return MnistSiameseDataIterator(itr0, itr1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we start training, let's set context to use GPU.\n",
        "\n",
        "We now define our computation graph for training, first by defining two variable for input images, and a variable for label. The image variables are fed into Siamese Lenet defined above, and the resulting prediction will be compared with the label to compute contrastive loss, which is also defined above. We can define a computation graph for validation in the same way.\n",
        "\n",
        "Let's also set our solver and monitor variables to track the progress of training. We use [Adam](https://arxiv.org/pdf/1412.6980.pdf) as our solver."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get context.\n",
        "from nnabla.ext_utils import get_extension_context\n",
        "ctx = get_extension_context('cudnn')\n",
        "nn.set_default_context(ctx)\n",
        "\n",
        "# Create CNN network for both training and testing.\n",
        "margin = 1.0  # Margin for contrastive loss.\n",
        "\n",
        "# TRAIN\n",
        "# Create input variables.\n",
        "batch_size = 128\n",
        "image0 = nn.Variable([batch_size, 1, 28, 28])\n",
        "image1 = nn.Variable([batch_size, 1, 28, 28])\n",
        "label = nn.Variable([batch_size])\n",
        "# Create prediction graph.\n",
        "pred = mnist_lenet_siamese(image0, image1, test=False)\n",
        "# Create loss function.\n",
        "loss = F.mean(contrastive_loss(pred, label, margin))\n",
        "\n",
        "# TEST\n",
        "# Create input variables.\n",
        "vimage0 = nn.Variable([batch_size, 1, 28, 28])\n",
        "vimage1 = nn.Variable([batch_size, 1, 28, 28])\n",
        "vlabel = nn.Variable([batch_size])\n",
        "# Create prediction graph.\n",
        "vpred = mnist_lenet_siamese(vimage0, vimage1, test=True)\n",
        "vloss = F.mean(contrastive_loss(vpred, vlabel, margin))\n",
        "\n",
        "# Create Solver.\n",
        "learning_rate = 1e-3\n",
        "solver = S.Adam(learning_rate)\n",
        "solver.set_parameters(nn.get_parameters())\n",
        "\n",
        "start_point = 0\n",
        "\n",
        "# Create monitor.\n",
        "import nnabla.monitor as M\n",
        "model_save_path = 'tmp.monitor.siamese'\n",
        "monitor = M.Monitor(model_save_path)\n",
        "monitor_loss = M.MonitorSeries(\"Training loss\", monitor, interval=10)\n",
        "monitor_time = M.MonitorTimeElapsed(\"Training time\", monitor, interval=100)\n",
        "monitor_vloss = M.MonitorSeries(\"Test loss\", monitor, interval=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After setting up data iterator variables using the slightly modified version we defined earlier, we can start the training. The final parameters obtained at the end of the training will be used for visualization of the learned feature embedding space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rng = np.random.RandomState(313)\n",
        "data = siamese_data_iterator(batch_size, True, rng)\n",
        "vdata = siamese_data_iterator(batch_size, False, rng)\n",
        "\n",
        "# Training loop.\n",
        "max_iter = 5000\n",
        "val_interval = 100\n",
        "val_iter = 10\n",
        "weight_decay = 0\n",
        "for i in range(start_point, max_iter):\n",
        "    if i % val_interval == 0:\n",
        "        # Validation\n",
        "        ve = 0.0\n",
        "        for j in range(val_iter):\n",
        "            vimage0.d, vimage1.d, vlabel.d = vdata.next()\n",
        "            vloss.forward(clear_buffer=True)\n",
        "            ve += vloss.d\n",
        "        monitor_vloss.add(i, ve / val_iter)\n",
        "    image0.d, image1.d, label.d = data.next()\n",
        "    solver.zero_grad()\n",
        "    # Training forward, backward and update\n",
        "    loss.forward(clear_no_need_grad=True)\n",
        "    loss.backward(clear_buffer=True)\n",
        "    solver.weight_decay(weight_decay)\n",
        "    solver.update()\n",
        "    monitor_loss.add(i, loss.d.copy())\n",
        "    monitor_time.add(i)\n",
        "\n",
        "# Comment out if you want to save the parameters\n",
        "# parameter_file = os.path.join(\n",
        "#     model_save_path, 'params_%06d.h5' % max_iter)\n",
        "# nn.save_parameters(parameter_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's visually confirm how each class of digit is represented in the feature embedding space that our model learned. We load 10,000 samples from MNIST, extract their features using LeNet, and plot it on a graph using dimensionality reduction technique called [t-SNE](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf). Each dot represents a sample, with each distinct color representing a unique class of digit. If the model was trained successfully, you should be able to see that the dots of the same color form a seemingly distinct group, which implies that the classification can be reliably performed using these features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 500\n",
        "\n",
        "# Create embedded network\n",
        "image = nn.Variable([batch_size, 1, 28, 28])\n",
        "feature = mnist_lenet_feature(image, test=True)\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "rng = np.random.RandomState(313)\n",
        "data = data_iterator_mnist(batch_size, train=False, rng=rng, shuffle=True)\n",
        "for i in range(10000 // batch_size):\n",
        "    image_data, label_data = data.next()\n",
        "    image.d = image_data / 255.\n",
        "    feature.forward(clear_buffer=True)\n",
        "    features.append(feature.d.copy())\n",
        "    labels.append(label_data.copy())\n",
        "features = np.vstack(features)\n",
        "labels = np.vstack(labels)\n",
        "\n",
        "# Visualize\n",
        "f = plt.figure(figsize=(16, 9))\n",
        "for i in range(10):\n",
        "    c = plt.cm.Set1(i / 10.)\n",
        "    plt.plot(features[labels.flat == i, 0].flatten(), features[\n",
        "              labels.flat == i, 1].flatten(), '.', c=c)\n",
        "plt.legend(list(map(str, range(10))))\n",
        "plt.grid()\n",
        "plt.savefig(os.path.join(model_save_path, \"embed.png\"))\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image('tmp.monitor.siamese/embed.png'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU", 
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
